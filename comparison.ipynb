{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61548688-cec3-4031-b010-592118535a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tienyu/anaconda3/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from mobileresunet import MobileResUNet\n",
    "from resunet import ResUNet\n",
    "from unet import UNet\n",
    "from datasets import EchoNetDataset\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8091876-3df7-408e-8e9a-544aa8844654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitSeg(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 learning_rate=1e-4,\n",
    "                 root_dir=\"/home/tienyu/data/EchoNet-Dynamic\"):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.learning_rate = learning_rate\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, _, masks, _ = batch\n",
    "        input_frames = torch.cat(inputs[1:])\n",
    "        masks = torch.cat(masks).float()\n",
    "\n",
    "        logits = self(input_frames)\n",
    "        loss = F.binary_cross_entropy(logits, masks)\n",
    "\n",
    "        tensorboard_logs = {'loss': {'train': loss}}\n",
    "        self.log('loss', loss, logger=True)\n",
    "        return {\"loss\": loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, _, masks, _ = batch\n",
    "        input_frames = torch.cat(inputs[1:])\n",
    "        masks = torch.cat(masks).float()\n",
    "\n",
    "        logits = self(input_frames)\n",
    "        loss = F.binary_cross_entropy(logits, masks)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'loss': {'val': val_loss}}\n",
    "        return {\"val_loss\": val_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    # Data hooks\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.echo_train = EchoNetDataset(root_dir=self.root_dir,\n",
    "                                             split=\"train\")\n",
    "            self.echo_val = EchoNetDataset(root_dir=self.root_dir, split=\"val\")\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.echo_test = EchoNetDataset(root_dir=self.root_dir,\n",
    "                                            split=\"test\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.echo_train,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.echo_val, batch_size=16, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.echo_test, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type          | Params\n",
      "-------------------------------------------\n",
      "0 | backbone | MobileResUNet | 4.4 M \n",
      "-------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.758    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6a9574f5f84742bc321f3d000445f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fd4624bada46a4b4a4a0000ed85d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "backbone = MobileResUNet(1, 1)\n",
    "model = LitSeg(backbone=backbone)\n",
    "tb_logger = pl_loggers.TensorBoardLogger('logs_mobileresunet/')\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss', every_n_val_epochs=1)\n",
    "trainer = pl.Trainer(gpus=AVAIL_GPUS,\n",
    "                     max_epochs=30,\n",
    "                     progress_bar_refresh_rate=20,\n",
    "                     logger=tb_logger,\n",
    "                     callbacks=[model_checkpoint])\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8917e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53f2da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs_cspresxunet/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad2ddd",
   "metadata": {},
   "source": [
    "## Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#    Author: Aaron Liu\n",
    "#    Email: tl254@duke.edu\n",
    "#    Created on: June 29 2021\n",
    "#    Code structure reference: https://github.com/milesial/Pytorch-UNet\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class LevelBlock(nn.Module):\n",
    "#     \"\"\"(BN ==> ReLU ==> Conv) x 2\"\"\"\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             in_channels,\n",
    "#             out_channels,\n",
    "#             stride=(1, 1),\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.stride = stride\n",
    "#         self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "#         self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "#         self.stacked_blocks1 = nn.Conv2d(in_channels,\n",
    "#                                          out_channels,\n",
    "#                                          kernel_size=3,\n",
    "#                                          padding=1,\n",
    "#                                          stride=self.stride[0],\n",
    "#                                          bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.stacked_blocks2 = nn.Conv2d(out_channels,\n",
    "#                                          out_channels,\n",
    "#                                          kernel_size=1,\n",
    "#                                          stride=self.stride[1],\n",
    "#                                          bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.stacked_blocks1(self.activation(self.bn1(x)))\n",
    "#         x = self.stacked_blocks2(self.activation(self.bn2(x)))\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class UpSamplingConcatenate(nn.Module):\n",
    "#     \"\"\"Upscaling\"\"\"\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.up = nn.ConvTranspose2d(in_channels,\n",
    "#                                      out_channels,\n",
    "#                                      kernel_size=2,\n",
    "#                                      stride=2)\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         x1 = self.up(x1)\n",
    "#         diffY = x2.size()[2] - x1.size()[2]\n",
    "#         diffX = x2.size()[3] - x1.size()[3]\n",
    "#         x1 = F.pad(\n",
    "#             x1,\n",
    "#             [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "#         x = torch.cat([x2, x1], dim=1)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d41ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#    Author: Aaron Liu\n",
    "#    Email: tl254@duke.edu\n",
    "#    Created on: June 29 2021\n",
    "# \"\"\"\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # from .cspresunet_parts import LevelBlock, UpSamplingConcatenate\n",
    "\n",
    "\n",
    "# class CSPResUNet(nn.Module):\n",
    "#     def __init__(self, n_channels, n_classes):\n",
    "#         super(CSPResUNet, self).__init__()\n",
    "#         self.n_channels = n_channels\n",
    "#         self.n_classes = n_classes\n",
    "\n",
    "#         # Encoding\n",
    "#         self.level1 = nn.Sequential(\n",
    "#             nn.Conv2d(n_channels, 64, kernel_size=3, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "#         )\n",
    "#         self.level2 = LevelBlock(64, 128, stride=(2, 1))\n",
    "#         self.level3 = LevelBlock(128, 256, stride=(2, 1))\n",
    "#         self.level4 = LevelBlock(256, 512, stride=(2, 1))\n",
    "#         self.level5 = LevelBlock(512, 256, stride=(1, 1))\n",
    "#         self.level6 = LevelBlock(256, 128, stride=(1, 1))\n",
    "#         self.level7 = LevelBlock(128, 64, stride=(1, 1))\n",
    "\n",
    "#         self.up1 = UpSamplingConcatenate(512, 256)\n",
    "#         self.up2 = UpSamplingConcatenate(256, 128)\n",
    "#         self.up3 = UpSamplingConcatenate(128, 64)\n",
    "\n",
    "#         self.shortcut1 = nn.Conv2d(n_channels, 64, kernel_size=1)\n",
    "#         self.shortcut2 = nn.Conv2d(64, 128, kernel_size=1, stride=2)\n",
    "#         self.shortcut3 = nn.Conv2d(128, 256, kernel_size=1, stride=2)\n",
    "#         self.shortcut5 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "#         self.shortcut6 = nn.Conv2d(256, 128, kernel_size=1)\n",
    "#         self.shortcut7 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "\n",
    "#         self.outconv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Encoding\n",
    "#         x1 = self.level1(x)\n",
    "        \n",
    "#         x2_in = x1 + self.shortcut1(x)\n",
    "#         x2 = self.level2(x2_in)\n",
    "#         x3_in = x2 + self.shortcut2(x1)\n",
    "#         x3 = self.level3(x3_in)\n",
    "#         x4_in = x3 + self.shortcut3(x2)\n",
    "\n",
    "#         # Bridge\n",
    "#         x4 = self.level4(x4_in)\n",
    "\n",
    "#         # Decoding\n",
    "#         x_cat = self.up1(x4, x4_in)\n",
    "#         x5 = self.level5(x_cat)\n",
    "#         x_cat = self.up2(x5 + self.shortcut5(x_cat), x3_in)\n",
    "#         x6 = self.level6(x_cat)\n",
    "#         x_cat = self.up3(x6 + self.shortcut6(x_cat), x2_in)\n",
    "#         x7 = self.level7(x_cat)\n",
    "#         x = self.outconv(x7 + self.shortcut7(x_cat))\n",
    "        \n",
    "#         # Sigmoid\n",
    "#         x = self.sigmoid(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a845cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(1,1,112,112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea4fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(model, input_size=(1,112,112), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc45b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b24c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
