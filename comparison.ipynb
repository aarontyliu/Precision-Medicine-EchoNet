{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61548688-cec3-4031-b010-592118535a12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cspresunet.cspunet_parts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_210985/3568418081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcspresunet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSPResUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mresunet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEchoNetDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Precision-Medicine-EchoNet/cspresunet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcspresunet_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSPResUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Precision-Medicine-EchoNet/cspresunet/cspresunet_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcspunet_parts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cspresunet.cspunet_parts'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from cspresunet import CSPResUNet\n",
    "from resunet import ResUNet\n",
    "from unet import UNet\n",
    "from datasets import EchoNetDataset\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8676d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSPUNet(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f40d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 56, 56]             216\n",
      "       BatchNorm2d-2           [-1, 24, 56, 56]              48\n",
      "              ReLU-3           [-1, 24, 56, 56]               0\n",
      "            Conv2d-4           [-1, 24, 56, 56]           5,184\n",
      "       BatchNorm2d-5           [-1, 24, 56, 56]              48\n",
      "              ReLU-6           [-1, 24, 56, 56]               0\n",
      "            Conv2d-7           [-1, 24, 56, 56]             576\n",
      "       BatchNorm2d-8           [-1, 24, 56, 56]              48\n",
      "       FusedMBConv-9           [-1, 24, 56, 56]               0\n",
      "           Conv2d-10           [-1, 24, 56, 56]           5,184\n",
      "      BatchNorm2d-11           [-1, 24, 56, 56]              48\n",
      "             ReLU-12           [-1, 24, 56, 56]               0\n",
      "           Conv2d-13           [-1, 24, 56, 56]             576\n",
      "      BatchNorm2d-14           [-1, 24, 56, 56]              48\n",
      "      FusedMBConv-15           [-1, 24, 56, 56]               0\n",
      "           Conv2d-16           [-1, 48, 56, 56]          10,368\n",
      "      BatchNorm2d-17           [-1, 48, 56, 56]              96\n",
      "             ReLU-18           [-1, 48, 56, 56]               0\n",
      "           Conv2d-19           [-1, 24, 56, 56]           1,152\n",
      "      BatchNorm2d-20           [-1, 24, 56, 56]              48\n",
      "      FusedMBConv-21           [-1, 24, 56, 56]               0\n",
      "           Conv2d-22           [-1, 48, 56, 56]          10,368\n",
      "      BatchNorm2d-23           [-1, 48, 56, 56]              96\n",
      "             ReLU-24           [-1, 48, 56, 56]               0\n",
      "           Conv2d-25           [-1, 48, 56, 56]           2,304\n",
      "      BatchNorm2d-26           [-1, 48, 56, 56]              96\n",
      "      FusedMBConv-27           [-1, 48, 56, 56]               0\n",
      "           Conv2d-28          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-29          [-1, 192, 56, 56]             384\n",
      "             ReLU-30          [-1, 192, 56, 56]               0\n",
      "           Conv2d-31           [-1, 48, 56, 56]           9,216\n",
      "      BatchNorm2d-32           [-1, 48, 56, 56]              96\n",
      "      FusedMBConv-33           [-1, 48, 56, 56]               0\n",
      "           Conv2d-34          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-35          [-1, 192, 56, 56]             384\n",
      "             ReLU-36          [-1, 192, 56, 56]               0\n",
      "           Conv2d-37           [-1, 64, 56, 56]          12,288\n",
      "      BatchNorm2d-38           [-1, 64, 56, 56]             128\n",
      "      FusedMBConv-39           [-1, 64, 56, 56]               0\n",
      "           Conv2d-40          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-41          [-1, 256, 56, 56]             512\n",
      "             ReLU-42          [-1, 256, 56, 56]               0\n",
      "           Conv2d-43          [-1, 256, 56, 56]           2,304\n",
      "      BatchNorm2d-44          [-1, 256, 56, 56]             512\n",
      "             ReLU-45          [-1, 256, 56, 56]               0\n",
      "           Conv2d-46             [-1, 64, 1, 1]          16,448\n",
      "           Conv2d-47            [-1, 256, 1, 1]          16,640\n",
      "           Conv2d-48           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-49           [-1, 64, 56, 56]             128\n",
      "           MBConv-50           [-1, 64, 56, 56]               0\n",
      "           Conv2d-51          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-52          [-1, 256, 56, 56]             512\n",
      "             ReLU-53          [-1, 256, 56, 56]               0\n",
      "           Conv2d-54          [-1, 256, 56, 56]           2,304\n",
      "      BatchNorm2d-55          [-1, 256, 56, 56]             512\n",
      "             ReLU-56          [-1, 256, 56, 56]               0\n",
      "           Conv2d-57             [-1, 64, 1, 1]          16,448\n",
      "           Conv2d-58            [-1, 256, 1, 1]          16,640\n",
      "           Conv2d-59           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-60           [-1, 64, 56, 56]             128\n",
      "           MBConv-61           [-1, 64, 56, 56]               0\n",
      "           Conv2d-62          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-63          [-1, 256, 56, 56]             512\n",
      "             ReLU-64          [-1, 256, 56, 56]               0\n",
      "           Conv2d-65          [-1, 256, 56, 56]           2,304\n",
      "      BatchNorm2d-66          [-1, 256, 56, 56]             512\n",
      "             ReLU-67          [-1, 256, 56, 56]               0\n",
      "           Conv2d-68             [-1, 64, 1, 1]          16,448\n",
      "           Conv2d-69            [-1, 256, 1, 1]          16,640\n",
      "           Conv2d-70           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-71           [-1, 64, 56, 56]             128\n",
      "           MBConv-72           [-1, 64, 56, 56]               0\n",
      "           Conv2d-73          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-74          [-1, 256, 56, 56]             512\n",
      "             ReLU-75          [-1, 256, 56, 56]               0\n",
      "           Conv2d-76          [-1, 256, 28, 28]           2,304\n",
      "      BatchNorm2d-77          [-1, 256, 28, 28]             512\n",
      "             ReLU-78          [-1, 256, 28, 28]               0\n",
      "           Conv2d-79             [-1, 64, 1, 1]          16,448\n",
      "           Conv2d-80            [-1, 256, 1, 1]          16,640\n",
      "           Conv2d-81          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-82          [-1, 128, 28, 28]             256\n",
      "           MBConv-83          [-1, 128, 28, 28]               0\n",
      "           Conv2d-84          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-85          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-86          [-1, 512, 28, 28]               0\n",
      "           Conv2d-87          [-1, 512, 28, 28]           4,608\n",
      "      BatchNorm2d-88          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-89          [-1, 512, 28, 28]               0\n",
      "           Conv2d-90            [-1, 128, 1, 1]          65,664\n",
      "           Conv2d-91            [-1, 512, 1, 1]          66,048\n",
      "           Conv2d-92          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "           MBConv-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "           Conv2d-98          [-1, 512, 28, 28]           4,608\n",
      "      BatchNorm2d-99          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-100          [-1, 512, 28, 28]               0\n",
      "          Conv2d-101            [-1, 128, 1, 1]          65,664\n",
      "          Conv2d-102            [-1, 512, 1, 1]          66,048\n",
      "          Conv2d-103          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-104          [-1, 128, 28, 28]             256\n",
      "          MBConv-105          [-1, 128, 28, 28]               0\n",
      "          Conv2d-106          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-107          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 512, 28, 28]           4,608\n",
      "     BatchNorm2d-110          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-111          [-1, 512, 28, 28]               0\n",
      "          Conv2d-112            [-1, 128, 1, 1]          65,664\n",
      "          Conv2d-113            [-1, 512, 1, 1]          66,048\n",
      "          Conv2d-114          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-115          [-1, 128, 28, 28]             256\n",
      "          MBConv-116          [-1, 128, 28, 28]               0\n",
      "          Conv2d-117          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-118          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-119          [-1, 512, 28, 28]               0\n",
      "          Conv2d-120          [-1, 512, 28, 28]           4,608\n",
      "     BatchNorm2d-121          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-122          [-1, 512, 28, 28]               0\n",
      "          Conv2d-123            [-1, 128, 1, 1]          65,664\n",
      "          Conv2d-124            [-1, 512, 1, 1]          66,048\n",
      "          Conv2d-125          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-126          [-1, 128, 28, 28]             256\n",
      "          MBConv-127          [-1, 128, 28, 28]               0\n",
      "          Conv2d-128          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-129          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-130          [-1, 512, 28, 28]               0\n",
      "          Conv2d-131          [-1, 512, 28, 28]           4,608\n",
      "     BatchNorm2d-132          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-133          [-1, 512, 28, 28]               0\n",
      "          Conv2d-134            [-1, 128, 1, 1]          65,664\n",
      "          Conv2d-135            [-1, 512, 1, 1]          66,048\n",
      "          Conv2d-136          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-137          [-1, 128, 28, 28]             256\n",
      "          MBConv-138          [-1, 128, 28, 28]               0\n",
      "          Conv2d-139          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-140          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-141          [-1, 512, 28, 28]               0\n",
      "          Conv2d-142          [-1, 512, 28, 28]           4,608\n",
      "     BatchNorm2d-143          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-144          [-1, 512, 28, 28]               0\n",
      "          Conv2d-145            [-1, 128, 1, 1]          65,664\n",
      "          Conv2d-146            [-1, 512, 1, 1]          66,048\n",
      "          Conv2d-147          [-1, 160, 28, 28]          81,920\n",
      "     BatchNorm2d-148          [-1, 160, 28, 28]             320\n",
      "          MBConv-149          [-1, 160, 28, 28]               0\n",
      "          Conv2d-150          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-151          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-152          [-1, 640, 28, 28]               0\n",
      "          Conv2d-153          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-154          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-155          [-1, 640, 28, 28]               0\n",
      "          Conv2d-156            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-157            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-158          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-159          [-1, 160, 28, 28]             320\n",
      "          MBConv-160          [-1, 160, 28, 28]               0\n",
      "          Conv2d-161          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-162          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-163          [-1, 640, 28, 28]               0\n",
      "          Conv2d-164          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-165          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-166          [-1, 640, 28, 28]               0\n",
      "          Conv2d-167            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-168            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-169          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-170          [-1, 160, 28, 28]             320\n",
      "          MBConv-171          [-1, 160, 28, 28]               0\n",
      "          Conv2d-172          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-173          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-174          [-1, 640, 28, 28]               0\n",
      "          Conv2d-175          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-176          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-177          [-1, 640, 28, 28]               0\n",
      "          Conv2d-178            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-179            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-180          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-181          [-1, 160, 28, 28]             320\n",
      "          MBConv-182          [-1, 160, 28, 28]               0\n",
      "          Conv2d-183          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-184          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-185          [-1, 640, 28, 28]               0\n",
      "          Conv2d-186          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-187          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-188          [-1, 640, 28, 28]               0\n",
      "          Conv2d-189            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-190            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-191          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-192          [-1, 160, 28, 28]             320\n",
      "          MBConv-193          [-1, 160, 28, 28]               0\n",
      "          Conv2d-194          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-195          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-196          [-1, 640, 28, 28]               0\n",
      "          Conv2d-197          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-198          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-199          [-1, 640, 28, 28]               0\n",
      "          Conv2d-200            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-201            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-202          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-203          [-1, 160, 28, 28]             320\n",
      "          MBConv-204          [-1, 160, 28, 28]               0\n",
      "          Conv2d-205          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-206          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-207          [-1, 640, 28, 28]               0\n",
      "          Conv2d-208          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-209          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-210          [-1, 640, 28, 28]               0\n",
      "          Conv2d-211            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-212            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-213          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-214          [-1, 160, 28, 28]             320\n",
      "          MBConv-215          [-1, 160, 28, 28]               0\n",
      "          Conv2d-216          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-217          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-218          [-1, 640, 28, 28]               0\n",
      "          Conv2d-219          [-1, 640, 28, 28]           5,760\n",
      "     BatchNorm2d-220          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-221          [-1, 640, 28, 28]               0\n",
      "          Conv2d-222            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-223            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-224          [-1, 160, 28, 28]         102,400\n",
      "     BatchNorm2d-225          [-1, 160, 28, 28]             320\n",
      "          MBConv-226          [-1, 160, 28, 28]               0\n",
      "          Conv2d-227          [-1, 640, 28, 28]         102,400\n",
      "     BatchNorm2d-228          [-1, 640, 28, 28]           1,280\n",
      "            ReLU-229          [-1, 640, 28, 28]               0\n",
      "          Conv2d-230          [-1, 640, 14, 14]           5,760\n",
      "     BatchNorm2d-231          [-1, 640, 14, 14]           1,280\n",
      "            ReLU-232          [-1, 640, 14, 14]               0\n",
      "          Conv2d-233            [-1, 160, 1, 1]         102,560\n",
      "          Conv2d-234            [-1, 640, 1, 1]         103,040\n",
      "          Conv2d-235          [-1, 256, 14, 14]         163,840\n",
      "     BatchNorm2d-236          [-1, 256, 14, 14]             512\n",
      "          MBConv-237          [-1, 256, 14, 14]               0\n",
      " ConvTranspose2d-238          [-1, 160, 28, 28]         164,000\n",
      "          Conv2d-239          [-1, 160, 28, 28]         460,800\n",
      "     BatchNorm2d-240          [-1, 160, 28, 28]             320\n",
      "            ReLU-241          [-1, 160, 28, 28]               0\n",
      "          Conv2d-242          [-1, 160, 28, 28]         230,400\n",
      "     BatchNorm2d-243          [-1, 160, 28, 28]             320\n",
      "            ReLU-244          [-1, 160, 28, 28]               0\n",
      "          Conv2d-245          [-1, 160, 28, 28]          51,360\n",
      "      DoubleConv-246          [-1, 160, 28, 28]               0\n",
      "              Up-247          [-1, 160, 28, 28]               0\n",
      " ConvTranspose2d-248          [-1, 128, 56, 56]          82,048\n",
      "          Conv2d-249          [-1, 128, 28, 28]         294,912\n",
      "     BatchNorm2d-250          [-1, 128, 28, 28]             256\n",
      "            ReLU-251          [-1, 128, 28, 28]               0\n",
      "          Conv2d-252          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-253          [-1, 128, 28, 28]             256\n",
      "            ReLU-254          [-1, 128, 28, 28]               0\n",
      "          Conv2d-255          [-1, 128, 28, 28]          32,896\n",
      "      DoubleConv-256          [-1, 128, 28, 28]               0\n",
      "              Up-257          [-1, 128, 28, 28]               0\n",
      " ConvTranspose2d-258           [-1, 64, 56, 56]          32,832\n",
      "          Conv2d-259           [-1, 64, 56, 56]          73,728\n",
      "     BatchNorm2d-260           [-1, 64, 56, 56]             128\n",
      "            ReLU-261           [-1, 64, 56, 56]               0\n",
      "          Conv2d-262           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-263           [-1, 64, 56, 56]             128\n",
      "            ReLU-264           [-1, 64, 56, 56]               0\n",
      "          Conv2d-265           [-1, 64, 56, 56]           8,256\n",
      "      DoubleConv-266           [-1, 64, 56, 56]               0\n",
      "              Up-267           [-1, 64, 56, 56]               0\n",
      " ConvTranspose2d-268         [-1, 48, 112, 112]          12,336\n",
      "          Conv2d-269           [-1, 48, 56, 56]          41,472\n",
      "     BatchNorm2d-270           [-1, 48, 56, 56]              96\n",
      "            ReLU-271           [-1, 48, 56, 56]               0\n",
      "          Conv2d-272           [-1, 48, 56, 56]          20,736\n",
      "     BatchNorm2d-273           [-1, 48, 56, 56]              96\n",
      "            ReLU-274           [-1, 48, 56, 56]               0\n",
      "          Conv2d-275           [-1, 48, 56, 56]           4,656\n",
      "      DoubleConv-276           [-1, 48, 56, 56]               0\n",
      "              Up-277           [-1, 48, 56, 56]               0\n",
      " ConvTranspose2d-278         [-1, 24, 112, 112]           4,632\n",
      "          Conv2d-279           [-1, 24, 56, 56]          10,368\n",
      "     BatchNorm2d-280           [-1, 24, 56, 56]              48\n",
      "            ReLU-281           [-1, 24, 56, 56]               0\n",
      "          Conv2d-282           [-1, 24, 56, 56]           5,184\n",
      "     BatchNorm2d-283           [-1, 24, 56, 56]              48\n",
      "            ReLU-284           [-1, 24, 56, 56]               0\n",
      "          Conv2d-285           [-1, 24, 56, 56]           1,176\n",
      "      DoubleConv-286           [-1, 24, 56, 56]               0\n",
      "              Up-287           [-1, 24, 56, 56]               0\n",
      " ConvTranspose2d-288         [-1, 24, 112, 112]           2,328\n",
      "          Conv2d-289           [-1, 24, 56, 56]          10,368\n",
      "     BatchNorm2d-290           [-1, 24, 56, 56]              48\n",
      "            ReLU-291           [-1, 24, 56, 56]               0\n",
      "          Conv2d-292           [-1, 24, 56, 56]           5,184\n",
      "     BatchNorm2d-293           [-1, 24, 56, 56]              48\n",
      "            ReLU-294           [-1, 24, 56, 56]               0\n",
      "          Conv2d-295           [-1, 24, 56, 56]           1,176\n",
      "      DoubleConv-296           [-1, 24, 56, 56]               0\n",
      "              Up-297           [-1, 24, 56, 56]               0\n",
      " ConvTranspose2d-298          [-1, 1, 112, 112]              97\n",
      "         Sigmoid-299          [-1, 1, 112, 112]               0\n",
      "================================================================\n",
      "Total params: 7,304,281\n",
      "Trainable params: 7,304,281\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 591.53\n",
      "Params size (MB): 27.86\n",
      "Estimated Total Size (MB): 619.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 112, 112), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8091876-3df7-408e-8e9a-544aa8844654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitSeg(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 learning_rate=1e-4,\n",
    "                 root_dir=\"/home/tienyu/data/EchoNet-Dynamic\"):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.learning_rate = learning_rate\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, _, masks, _ = batch\n",
    "        input_frames = torch.cat(inputs[1:])\n",
    "        masks = torch.cat(masks).float()\n",
    "\n",
    "        logits = self(input_frames)\n",
    "        loss = F.binary_cross_entropy(logits, masks)\n",
    "\n",
    "        tensorboard_logs = {'loss': {'train': loss}}\n",
    "        self.log('loss', loss, logger=True)\n",
    "        return {\"loss\": loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, _, masks, _ = batch\n",
    "        input_frames = torch.cat(inputs[1:])\n",
    "        masks = torch.cat(masks).float()\n",
    "\n",
    "        logits = self(input_frames)\n",
    "        loss = F.binary_cross_entropy(logits, masks)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'loss': {'val': val_loss}}\n",
    "        return {\"val_loss\": val_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    # Data hooks\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.echo_train = EchoNetDataset(root_dir=self.root_dir,\n",
    "                                             split=\"train\")\n",
    "            self.echo_val = EchoNetDataset(root_dir=self.root_dir, split=\"val\")\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.echo_test = EchoNetDataset(root_dir=self.root_dir,\n",
    "                                            split=\"test\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.echo_train,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.echo_val, batch_size=8, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.echo_test, batch_size=8, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1e3a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "backbone = CSPUNet(1, 1)\n",
    "model = LitSeg(backbone=backbone)\n",
    "tb_logger = pl_loggers.TensorBoardLogger('logs_cspunet/')\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss', every_n_val_epochs=1)\n",
    "trainer = pl.Trainer(gpus=AVAIL_GPUS,\n",
    "                     max_epochs=30,\n",
    "                     progress_bar_refresh_rate=20,\n",
    "                     logger=tb_logger,\n",
    "                     callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b63aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | backbone | CSPUNet | 3.6 M \n",
      "-------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.267    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547f2db4747349f4810796324f7ae245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709cd0a0820d475d95b19fbfe0c0efa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tienyu/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:895: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89529c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa35231f912144f28cd07c275e6a0bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_loss': 0.27056142687797546}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.27056142687797546}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14950ef1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f4bce70410c3bc1a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f4bce70410c3bc1a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs_cspunet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dad3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
