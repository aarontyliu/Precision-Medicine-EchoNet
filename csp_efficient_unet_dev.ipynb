{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "247aa212-676d-4176-8cb0-be847d29cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cspunet import CSPUNet\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d5198579-8d31-4bb8-af2e-c88bfe2fe4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Author: Aaron Liu\n",
    "   Email: tl254@duke.edu\n",
    "   Created on: July 2 2021\n",
    "   Code structure reference: https://github.com/milesial/Pytorch-UNet\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FusedMBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, se=True):\n",
    "        super().__init__()\n",
    "        self.se = se\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.skip_connection = (\n",
    "            self.stride == 1 and self.in_channels == self.out_channels\n",
    "        )\n",
    "        self.half = 0\n",
    "        if self.skip_connection:\n",
    "            self.half = self.in_channels // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            self.in_channels - self.half,\n",
    "            4 * (self.in_channels - self.half),\n",
    "            kernel_size=3,\n",
    "            bias=False,\n",
    "            padding=self.kernel_size // 2,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(4 * (self.in_channels - self.half))\n",
    "        if self.se:\n",
    "            squeezed_channels = 4 * (self.in_channels - self.half)\n",
    "            self.reduce = nn.Conv2d(\n",
    "                in_channels=4 * (self.in_channels - self.half),\n",
    "                out_channels=squeezed_channels,\n",
    "                kernel_size=1,\n",
    "            )\n",
    "            self.expand = nn.Conv2d(\n",
    "                in_channels=squeezed_channels,\n",
    "                out_channels=4 * (self.in_channels - self.half),\n",
    "                kernel_size=1,\n",
    "            )\n",
    "\n",
    "        self.projection = nn.Conv2d(\n",
    "            4 * (self.in_channels - self.half),\n",
    "            self.out_channels - self.half,\n",
    "            kernel_size=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels - self.half)\n",
    "\n",
    "    def forward(self, x):\n",
    "        part1, part2 = x[:, : self.half], x[:, self.half :]\n",
    "        out = self.activation(self.bn1(self.conv(part2)))\n",
    "\n",
    "        # squeeze and excitation block\n",
    "        if self.se:\n",
    "            out_squeezed = F.adaptive_avg_pool2d(out, 1)\n",
    "            out_squeezed = F.relu(self.reduce(out_squeezed))\n",
    "            out_squeezed = self.expand(out_squeezed)\n",
    "            out = torch.sigmoid(out_squeezed) * out\n",
    "\n",
    "        out = self.bn2(self.projection(out))\n",
    "\n",
    "        if self.skip_connection:\n",
    "            out = torch.cat([out + part2, part1], dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, t=4, kernel_size=3, stride=1, se=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.se = se\n",
    "        self.t = t\n",
    "        self.in_channels = in_channels\n",
    "        self.mid_channels = self.in_channels * self.t\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.skip_connection = (\n",
    "            self.stride == 1 and self.in_channels == self.out_channels\n",
    "        )\n",
    "        self.half = 0\n",
    "        if self.skip_connection:\n",
    "            self.half = self.in_channels // 2\n",
    "            self.expansion = nn.Conv2d(\n",
    "                self.half, self.mid_channels - self.half, kernel_size=1, bias=False\n",
    "            )\n",
    "        else:\n",
    "            self.expansion = nn.Conv2d(\n",
    "                self.in_channels, self.mid_channels, kernel_size=1, bias=False\n",
    "            )\n",
    "        self.bn1 = nn.BatchNorm2d(self.mid_channels - self.half)\n",
    "        self.dwise = nn.Conv2d(\n",
    "            self.mid_channels - self.half,\n",
    "            self.mid_channels - self.half,\n",
    "            groups=self.mid_channels - self.half,\n",
    "            kernel_size=self.kernel_size,\n",
    "            bias=False,\n",
    "            stride=self.stride,\n",
    "            padding=self.kernel_size // 2,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(self.mid_channels - self.half)\n",
    "        self.projection = nn.Conv2d(\n",
    "            self.mid_channels - self.half,\n",
    "            self.out_channels - self.half,\n",
    "            kernel_size=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(self.out_channels - self.half)\n",
    "        if self.se:\n",
    "            se_ratio = 0.25\n",
    "            squeezed_channels = int((self.mid_channels - self.half) * se_ratio)\n",
    "            self.reduce = nn.Conv2d(\n",
    "                in_channels=self.mid_channels - self.half,\n",
    "                out_channels=squeezed_channels,\n",
    "                kernel_size=1,\n",
    "            )\n",
    "            self.expand = nn.Conv2d(\n",
    "                in_channels=squeezed_channels,\n",
    "                out_channels=self.mid_channels - self.half,\n",
    "                kernel_size=1,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        part1, part2 = x[:, : self.half], x[:, self.half :]\n",
    "        out = self.activation(self.bn1(self.expansion(part2)))\n",
    "        out = self.activation(self.bn2(self.dwise(out)))\n",
    "\n",
    "        # squeeze and excitation block\n",
    "        if self.se:\n",
    "            out_squeezed = F.adaptive_avg_pool2d(out, 1)\n",
    "            out_squeezed = F.relu(self.reduce(out_squeezed))\n",
    "            out_squeezed = self.expand(out_squeezed)\n",
    "            out = torch.sigmoid(out_squeezed) * out\n",
    "\n",
    "        out = self.bn3(self.projection(out))\n",
    "\n",
    "        if self.skip_connection:\n",
    "            out = torch.cat([out + part2, part1], dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        return out + self.shortcut(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        #         self.half = out_channels\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8f9e4fcb-2a1e-4ed2-b063-e23c27da7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(CSPUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Encoding\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 24, kernel_size=3, padding=1, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.down1 = nn.Sequential(*(2 * [FusedMBConv(24, 24, stride=1)]))\n",
    "        self.down2 = nn.Sequential(\n",
    "            *(3 * [FusedMBConv(24, 24)] + [FusedMBConv(24, 48, stride=2)])\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            *(3 * [FusedMBConv(48, 48)] + [FusedMBConv(48, 64, stride=2)])\n",
    "        )\n",
    "        self.down4 = nn.Sequential(\n",
    "            *(5 * [MBConv(64, 64, t=4)] + [MBConv(64, 128, stride=2, t=4)])\n",
    "        )\n",
    "        self.down5 = nn.Sequential(\n",
    "            *(8 * [MBConv(128, 128, t=6)] + [MBConv(128, 160, stride=1, t=6)])\n",
    "        )\n",
    "        self.down6 = nn.Sequential(\n",
    "            *(14 * [MBConv(160, 160, t=6)] + [MBConv(160, 256, stride=2, t=6)])\n",
    "        )\n",
    "\n",
    "        self.up1 = Up(256, 160)\n",
    "        self.up2 = Up(160, 128)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.up4 = Up(64, 48)\n",
    "        self.up5 = Up(48, 24)\n",
    "        self.up6 = Up(24, 24)\n",
    "\n",
    "        self.outconv = nn.ConvTranspose2d(24, n_classes, kernel_size=2, stride=2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        x0 = self.stem(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.down5(x4)\n",
    "        x6 = self.down6(x5)\n",
    "\n",
    "        # Decoding\n",
    "        x = self.up1(x6, x5)\n",
    "        x = self.up2(x, x4)\n",
    "        x = self.up3(x, x3)\n",
    "        x = self.up4(x, x2)\n",
    "        x = self.up5(x, x1)\n",
    "        x = self.up6(x, x0)\n",
    "\n",
    "        # Head\n",
    "        x = self.sigmoid(self.outconv(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "732ab2fd-96d7-4ce7-8ecc-3e45435bcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = CSPUNet(1, 1)\n",
    "x = torch.rand(2, 1, 112, 112)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8c16cf7d-243d-403e-a927-3c893eda5304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 112, 112])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "d6e90010-6790-43a4-bb10-7994880f646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 56, 56]             216\n",
      "       BatchNorm2d-2           [-1, 24, 56, 56]              48\n",
      "              ReLU-3           [-1, 24, 56, 56]               0\n",
      "            Conv2d-4           [-1, 48, 56, 56]           5,184\n",
      "       BatchNorm2d-5           [-1, 48, 56, 56]              96\n",
      "              ReLU-6           [-1, 48, 56, 56]               0\n",
      "            Conv2d-7             [-1, 48, 1, 1]           2,352\n",
      "            Conv2d-8             [-1, 48, 1, 1]           2,352\n",
      "            Conv2d-9           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-10           [-1, 12, 56, 56]              24\n",
      "      FusedMBConv-11           [-1, 24, 56, 56]               0\n",
      "           Conv2d-12           [-1, 48, 56, 56]           5,184\n",
      "      BatchNorm2d-13           [-1, 48, 56, 56]              96\n",
      "             ReLU-14           [-1, 48, 56, 56]               0\n",
      "           Conv2d-15             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-16             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-17           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-18           [-1, 12, 56, 56]              24\n",
      "      FusedMBConv-19           [-1, 24, 56, 56]               0\n",
      "           Conv2d-20           [-1, 48, 56, 56]           5,184\n",
      "      BatchNorm2d-21           [-1, 48, 56, 56]              96\n",
      "             ReLU-22           [-1, 48, 56, 56]               0\n",
      "           Conv2d-23             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-24             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-25           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-26           [-1, 12, 56, 56]              24\n",
      "      FusedMBConv-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28           [-1, 48, 56, 56]           5,184\n",
      "      BatchNorm2d-29           [-1, 48, 56, 56]              96\n",
      "             ReLU-30           [-1, 48, 56, 56]               0\n",
      "           Conv2d-31             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-32             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-33           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-34           [-1, 12, 56, 56]              24\n",
      "      FusedMBConv-35           [-1, 24, 56, 56]               0\n",
      "           Conv2d-36           [-1, 48, 56, 56]           5,184\n",
      "      BatchNorm2d-37           [-1, 48, 56, 56]              96\n",
      "             ReLU-38           [-1, 48, 56, 56]               0\n",
      "           Conv2d-39             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-40             [-1, 48, 1, 1]           2,352\n",
      "           Conv2d-41           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-42           [-1, 12, 56, 56]              24\n",
      "      FusedMBConv-43           [-1, 24, 56, 56]               0\n",
      "           Conv2d-44           [-1, 96, 56, 56]          20,736\n",
      "      BatchNorm2d-45           [-1, 96, 56, 56]             192\n",
      "             ReLU-46           [-1, 96, 56, 56]               0\n",
      "           Conv2d-47             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-48             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-49           [-1, 48, 56, 56]           4,608\n",
      "      BatchNorm2d-50           [-1, 48, 56, 56]              96\n",
      "      FusedMBConv-51           [-1, 48, 56, 56]               0\n",
      "           Conv2d-52           [-1, 96, 56, 56]          20,736\n",
      "      BatchNorm2d-53           [-1, 96, 56, 56]             192\n",
      "             ReLU-54           [-1, 96, 56, 56]               0\n",
      "           Conv2d-55             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-56             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-57           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-58           [-1, 24, 56, 56]              48\n",
      "      FusedMBConv-59           [-1, 48, 56, 56]               0\n",
      "           Conv2d-60           [-1, 96, 56, 56]          20,736\n",
      "      BatchNorm2d-61           [-1, 96, 56, 56]             192\n",
      "             ReLU-62           [-1, 96, 56, 56]               0\n",
      "           Conv2d-63             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-64             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-65           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-66           [-1, 24, 56, 56]              48\n",
      "      FusedMBConv-67           [-1, 48, 56, 56]               0\n",
      "           Conv2d-68           [-1, 96, 56, 56]          20,736\n",
      "      BatchNorm2d-69           [-1, 96, 56, 56]             192\n",
      "             ReLU-70           [-1, 96, 56, 56]               0\n",
      "           Conv2d-71             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-72             [-1, 96, 1, 1]           9,312\n",
      "           Conv2d-73           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-74           [-1, 24, 56, 56]              48\n",
      "      FusedMBConv-75           [-1, 48, 56, 56]               0\n",
      "           Conv2d-76          [-1, 192, 56, 56]          82,944\n",
      "      BatchNorm2d-77          [-1, 192, 56, 56]             384\n",
      "             ReLU-78          [-1, 192, 56, 56]               0\n",
      "           Conv2d-79            [-1, 192, 1, 1]          37,056\n",
      "           Conv2d-80            [-1, 192, 1, 1]          37,056\n",
      "           Conv2d-81           [-1, 64, 56, 56]          12,288\n",
      "      BatchNorm2d-82           [-1, 64, 56, 56]             128\n",
      "      FusedMBConv-83           [-1, 64, 56, 56]               0\n",
      "           Conv2d-84          [-1, 224, 56, 56]           7,168\n",
      "      BatchNorm2d-85          [-1, 224, 56, 56]             448\n",
      "             ReLU-86          [-1, 224, 56, 56]               0\n",
      "           Conv2d-87          [-1, 224, 56, 56]           2,016\n",
      "      BatchNorm2d-88          [-1, 224, 56, 56]             448\n",
      "             ReLU-89          [-1, 224, 56, 56]               0\n",
      "           Conv2d-90             [-1, 56, 1, 1]          12,600\n",
      "           Conv2d-91            [-1, 224, 1, 1]          12,768\n",
      "           Conv2d-92           [-1, 32, 56, 56]           7,168\n",
      "      BatchNorm2d-93           [-1, 32, 56, 56]              64\n",
      "           MBConv-94           [-1, 64, 56, 56]               0\n",
      "           Conv2d-95          [-1, 224, 56, 56]           7,168\n",
      "      BatchNorm2d-96          [-1, 224, 56, 56]             448\n",
      "             ReLU-97          [-1, 224, 56, 56]               0\n",
      "           Conv2d-98          [-1, 224, 56, 56]           2,016\n",
      "      BatchNorm2d-99          [-1, 224, 56, 56]             448\n",
      "            ReLU-100          [-1, 224, 56, 56]               0\n",
      "          Conv2d-101             [-1, 56, 1, 1]          12,600\n",
      "          Conv2d-102            [-1, 224, 1, 1]          12,768\n",
      "          Conv2d-103           [-1, 32, 56, 56]           7,168\n",
      "     BatchNorm2d-104           [-1, 32, 56, 56]              64\n",
      "          MBConv-105           [-1, 64, 56, 56]               0\n",
      "          Conv2d-106          [-1, 224, 56, 56]           7,168\n",
      "     BatchNorm2d-107          [-1, 224, 56, 56]             448\n",
      "            ReLU-108          [-1, 224, 56, 56]               0\n",
      "          Conv2d-109          [-1, 224, 56, 56]           2,016\n",
      "     BatchNorm2d-110          [-1, 224, 56, 56]             448\n",
      "            ReLU-111          [-1, 224, 56, 56]               0\n",
      "          Conv2d-112             [-1, 56, 1, 1]          12,600\n",
      "          Conv2d-113            [-1, 224, 1, 1]          12,768\n",
      "          Conv2d-114           [-1, 32, 56, 56]           7,168\n",
      "     BatchNorm2d-115           [-1, 32, 56, 56]              64\n",
      "          MBConv-116           [-1, 64, 56, 56]               0\n",
      "          Conv2d-117          [-1, 224, 56, 56]           7,168\n",
      "     BatchNorm2d-118          [-1, 224, 56, 56]             448\n",
      "            ReLU-119          [-1, 224, 56, 56]               0\n",
      "          Conv2d-120          [-1, 224, 56, 56]           2,016\n",
      "     BatchNorm2d-121          [-1, 224, 56, 56]             448\n",
      "            ReLU-122          [-1, 224, 56, 56]               0\n",
      "          Conv2d-123             [-1, 56, 1, 1]          12,600\n",
      "          Conv2d-124            [-1, 224, 1, 1]          12,768\n",
      "          Conv2d-125           [-1, 32, 56, 56]           7,168\n",
      "     BatchNorm2d-126           [-1, 32, 56, 56]              64\n",
      "          MBConv-127           [-1, 64, 56, 56]               0\n",
      "          Conv2d-128          [-1, 224, 56, 56]           7,168\n",
      "     BatchNorm2d-129          [-1, 224, 56, 56]             448\n",
      "            ReLU-130          [-1, 224, 56, 56]               0\n",
      "          Conv2d-131          [-1, 224, 56, 56]           2,016\n",
      "     BatchNorm2d-132          [-1, 224, 56, 56]             448\n",
      "            ReLU-133          [-1, 224, 56, 56]               0\n",
      "          Conv2d-134             [-1, 56, 1, 1]          12,600\n",
      "          Conv2d-135            [-1, 224, 1, 1]          12,768\n",
      "          Conv2d-136           [-1, 32, 56, 56]           7,168\n",
      "     BatchNorm2d-137           [-1, 32, 56, 56]              64\n",
      "          MBConv-138           [-1, 64, 56, 56]               0\n",
      "          Conv2d-139          [-1, 256, 56, 56]          16,384\n",
      "     BatchNorm2d-140          [-1, 256, 56, 56]             512\n",
      "            ReLU-141          [-1, 256, 56, 56]               0\n",
      "          Conv2d-142          [-1, 256, 28, 28]           2,304\n",
      "     BatchNorm2d-143          [-1, 256, 28, 28]             512\n",
      "            ReLU-144          [-1, 256, 28, 28]               0\n",
      "          Conv2d-145             [-1, 64, 1, 1]          16,448\n",
      "          Conv2d-146            [-1, 256, 1, 1]          16,640\n",
      "          Conv2d-147          [-1, 128, 28, 28]          32,768\n",
      "     BatchNorm2d-148          [-1, 128, 28, 28]             256\n",
      "          MBConv-149          [-1, 128, 28, 28]               0\n",
      "          Conv2d-150          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-151          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-152          [-1, 704, 28, 28]               0\n",
      "          Conv2d-153          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-154          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-155          [-1, 704, 28, 28]               0\n",
      "          Conv2d-156            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-157            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-158           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-159           [-1, 64, 28, 28]             128\n",
      "          MBConv-160          [-1, 128, 28, 28]               0\n",
      "          Conv2d-161          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-162          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-163          [-1, 704, 28, 28]               0\n",
      "          Conv2d-164          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-165          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-166          [-1, 704, 28, 28]               0\n",
      "          Conv2d-167            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-168            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-169           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-170           [-1, 64, 28, 28]             128\n",
      "          MBConv-171          [-1, 128, 28, 28]               0\n",
      "          Conv2d-172          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-173          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-174          [-1, 704, 28, 28]               0\n",
      "          Conv2d-175          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-176          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-177          [-1, 704, 28, 28]               0\n",
      "          Conv2d-178            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-179            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-180           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-181           [-1, 64, 28, 28]             128\n",
      "          MBConv-182          [-1, 128, 28, 28]               0\n",
      "          Conv2d-183          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-184          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-185          [-1, 704, 28, 28]               0\n",
      "          Conv2d-186          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-187          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-188          [-1, 704, 28, 28]               0\n",
      "          Conv2d-189            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-190            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-191           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-192           [-1, 64, 28, 28]             128\n",
      "          MBConv-193          [-1, 128, 28, 28]               0\n",
      "          Conv2d-194          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-195          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-196          [-1, 704, 28, 28]               0\n",
      "          Conv2d-197          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-198          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-199          [-1, 704, 28, 28]               0\n",
      "          Conv2d-200            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-201            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-202           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-203           [-1, 64, 28, 28]             128\n",
      "          MBConv-204          [-1, 128, 28, 28]               0\n",
      "          Conv2d-205          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-206          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-207          [-1, 704, 28, 28]               0\n",
      "          Conv2d-208          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-209          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-210          [-1, 704, 28, 28]               0\n",
      "          Conv2d-211            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-212            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-213           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-214           [-1, 64, 28, 28]             128\n",
      "          MBConv-215          [-1, 128, 28, 28]               0\n",
      "          Conv2d-216          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-217          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-218          [-1, 704, 28, 28]               0\n",
      "          Conv2d-219          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-220          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-221          [-1, 704, 28, 28]               0\n",
      "          Conv2d-222            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-223            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-224           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-225           [-1, 64, 28, 28]             128\n",
      "          MBConv-226          [-1, 128, 28, 28]               0\n",
      "          Conv2d-227          [-1, 704, 28, 28]          45,056\n",
      "     BatchNorm2d-228          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-229          [-1, 704, 28, 28]               0\n",
      "          Conv2d-230          [-1, 704, 28, 28]           6,336\n",
      "     BatchNorm2d-231          [-1, 704, 28, 28]           1,408\n",
      "            ReLU-232          [-1, 704, 28, 28]               0\n",
      "          Conv2d-233            [-1, 176, 1, 1]         124,080\n",
      "          Conv2d-234            [-1, 704, 1, 1]         124,608\n",
      "          Conv2d-235           [-1, 64, 28, 28]          45,056\n",
      "     BatchNorm2d-236           [-1, 64, 28, 28]             128\n",
      "          MBConv-237          [-1, 128, 28, 28]               0\n",
      "          Conv2d-238          [-1, 768, 28, 28]          98,304\n",
      "     BatchNorm2d-239          [-1, 768, 28, 28]           1,536\n",
      "            ReLU-240          [-1, 768, 28, 28]               0\n",
      "          Conv2d-241          [-1, 768, 28, 28]           6,912\n",
      "     BatchNorm2d-242          [-1, 768, 28, 28]           1,536\n",
      "            ReLU-243          [-1, 768, 28, 28]               0\n",
      "          Conv2d-244            [-1, 192, 1, 1]         147,648\n",
      "          Conv2d-245            [-1, 768, 1, 1]         148,224\n",
      "          Conv2d-246          [-1, 160, 28, 28]         122,880\n",
      "     BatchNorm2d-247          [-1, 160, 28, 28]             320\n",
      "          MBConv-248          [-1, 160, 28, 28]               0\n",
      "          Conv2d-249          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-250          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-251          [-1, 880, 28, 28]               0\n",
      "          Conv2d-252          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-253          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-254          [-1, 880, 28, 28]               0\n",
      "          Conv2d-255            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-256            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-257           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-258           [-1, 80, 28, 28]             160\n",
      "          MBConv-259          [-1, 160, 28, 28]               0\n",
      "          Conv2d-260          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-261          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-262          [-1, 880, 28, 28]               0\n",
      "          Conv2d-263          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-264          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-265          [-1, 880, 28, 28]               0\n",
      "          Conv2d-266            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-267            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-268           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-269           [-1, 80, 28, 28]             160\n",
      "          MBConv-270          [-1, 160, 28, 28]               0\n",
      "          Conv2d-271          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-272          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-273          [-1, 880, 28, 28]               0\n",
      "          Conv2d-274          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-275          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-276          [-1, 880, 28, 28]               0\n",
      "          Conv2d-277            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-278            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-279           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-280           [-1, 80, 28, 28]             160\n",
      "          MBConv-281          [-1, 160, 28, 28]               0\n",
      "          Conv2d-282          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-283          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-284          [-1, 880, 28, 28]               0\n",
      "          Conv2d-285          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-286          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-287          [-1, 880, 28, 28]               0\n",
      "          Conv2d-288            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-289            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-290           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-291           [-1, 80, 28, 28]             160\n",
      "          MBConv-292          [-1, 160, 28, 28]               0\n",
      "          Conv2d-293          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-294          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-295          [-1, 880, 28, 28]               0\n",
      "          Conv2d-296          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-297          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-298          [-1, 880, 28, 28]               0\n",
      "          Conv2d-299            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-300            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-301           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-302           [-1, 80, 28, 28]             160\n",
      "          MBConv-303          [-1, 160, 28, 28]               0\n",
      "          Conv2d-304          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-305          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-306          [-1, 880, 28, 28]               0\n",
      "          Conv2d-307          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-308          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-309          [-1, 880, 28, 28]               0\n",
      "          Conv2d-310            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-311            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-312           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-313           [-1, 80, 28, 28]             160\n",
      "          MBConv-314          [-1, 160, 28, 28]               0\n",
      "          Conv2d-315          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-316          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-317          [-1, 880, 28, 28]               0\n",
      "          Conv2d-318          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-319          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-320          [-1, 880, 28, 28]               0\n",
      "          Conv2d-321            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-322            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-323           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-324           [-1, 80, 28, 28]             160\n",
      "          MBConv-325          [-1, 160, 28, 28]               0\n",
      "          Conv2d-326          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-327          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-328          [-1, 880, 28, 28]               0\n",
      "          Conv2d-329          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-330          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-331          [-1, 880, 28, 28]               0\n",
      "          Conv2d-332            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-333            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-334           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-335           [-1, 80, 28, 28]             160\n",
      "          MBConv-336          [-1, 160, 28, 28]               0\n",
      "          Conv2d-337          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-338          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-339          [-1, 880, 28, 28]               0\n",
      "          Conv2d-340          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-341          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-342          [-1, 880, 28, 28]               0\n",
      "          Conv2d-343            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-344            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-345           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-346           [-1, 80, 28, 28]             160\n",
      "          MBConv-347          [-1, 160, 28, 28]               0\n",
      "          Conv2d-348          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-349          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-350          [-1, 880, 28, 28]               0\n",
      "          Conv2d-351          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-352          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-353          [-1, 880, 28, 28]               0\n",
      "          Conv2d-354            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-355            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-356           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-357           [-1, 80, 28, 28]             160\n",
      "          MBConv-358          [-1, 160, 28, 28]               0\n",
      "          Conv2d-359          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-360          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-361          [-1, 880, 28, 28]               0\n",
      "          Conv2d-362          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-363          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-364          [-1, 880, 28, 28]               0\n",
      "          Conv2d-365            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-366            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-367           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-368           [-1, 80, 28, 28]             160\n",
      "          MBConv-369          [-1, 160, 28, 28]               0\n",
      "          Conv2d-370          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-371          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-372          [-1, 880, 28, 28]               0\n",
      "          Conv2d-373          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-374          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-375          [-1, 880, 28, 28]               0\n",
      "          Conv2d-376            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-377            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-378           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-379           [-1, 80, 28, 28]             160\n",
      "          MBConv-380          [-1, 160, 28, 28]               0\n",
      "          Conv2d-381          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-382          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-383          [-1, 880, 28, 28]               0\n",
      "          Conv2d-384          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-385          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-386          [-1, 880, 28, 28]               0\n",
      "          Conv2d-387            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-388            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-389           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-390           [-1, 80, 28, 28]             160\n",
      "          MBConv-391          [-1, 160, 28, 28]               0\n",
      "          Conv2d-392          [-1, 880, 28, 28]          70,400\n",
      "     BatchNorm2d-393          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-394          [-1, 880, 28, 28]               0\n",
      "          Conv2d-395          [-1, 880, 28, 28]           7,920\n",
      "     BatchNorm2d-396          [-1, 880, 28, 28]           1,760\n",
      "            ReLU-397          [-1, 880, 28, 28]               0\n",
      "          Conv2d-398            [-1, 220, 1, 1]         193,820\n",
      "          Conv2d-399            [-1, 880, 1, 1]         194,480\n",
      "          Conv2d-400           [-1, 80, 28, 28]          70,400\n",
      "     BatchNorm2d-401           [-1, 80, 28, 28]             160\n",
      "          MBConv-402          [-1, 160, 28, 28]               0\n",
      "          Conv2d-403          [-1, 960, 28, 28]         153,600\n",
      "     BatchNorm2d-404          [-1, 960, 28, 28]           1,920\n",
      "            ReLU-405          [-1, 960, 28, 28]               0\n",
      "          Conv2d-406          [-1, 960, 14, 14]           8,640\n",
      "     BatchNorm2d-407          [-1, 960, 14, 14]           1,920\n",
      "            ReLU-408          [-1, 960, 14, 14]               0\n",
      "          Conv2d-409            [-1, 240, 1, 1]         230,640\n",
      "          Conv2d-410            [-1, 960, 1, 1]         231,360\n",
      "          Conv2d-411          [-1, 256, 14, 14]         245,760\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "          MBConv-413          [-1, 256, 14, 14]               0\n",
      " ConvTranspose2d-414          [-1, 160, 28, 28]         164,000\n",
      "          Conv2d-415          [-1, 160, 28, 28]         460,960\n",
      "     BatchNorm2d-416          [-1, 160, 28, 28]             320\n",
      "            ReLU-417          [-1, 160, 28, 28]               0\n",
      "          Conv2d-418          [-1, 160, 28, 28]         230,560\n",
      "     BatchNorm2d-419          [-1, 160, 28, 28]             320\n",
      "            ReLU-420          [-1, 160, 28, 28]               0\n",
      "          Conv2d-421          [-1, 160, 28, 28]          51,360\n",
      "      DoubleConv-422          [-1, 160, 28, 28]               0\n",
      "              Up-423          [-1, 160, 28, 28]               0\n",
      " ConvTranspose2d-424          [-1, 128, 56, 56]          82,048\n",
      "          Conv2d-425          [-1, 128, 28, 28]         295,040\n",
      "     BatchNorm2d-426          [-1, 128, 28, 28]             256\n",
      "            ReLU-427          [-1, 128, 28, 28]               0\n",
      "          Conv2d-428          [-1, 128, 28, 28]         147,584\n",
      "     BatchNorm2d-429          [-1, 128, 28, 28]             256\n",
      "            ReLU-430          [-1, 128, 28, 28]               0\n",
      "          Conv2d-431          [-1, 128, 28, 28]          32,896\n",
      "      DoubleConv-432          [-1, 128, 28, 28]               0\n",
      "              Up-433          [-1, 128, 28, 28]               0\n",
      " ConvTranspose2d-434           [-1, 64, 56, 56]          32,832\n",
      "          Conv2d-435           [-1, 64, 56, 56]          73,792\n",
      "     BatchNorm2d-436           [-1, 64, 56, 56]             128\n",
      "            ReLU-437           [-1, 64, 56, 56]               0\n",
      "          Conv2d-438           [-1, 64, 56, 56]          36,928\n",
      "     BatchNorm2d-439           [-1, 64, 56, 56]             128\n",
      "            ReLU-440           [-1, 64, 56, 56]               0\n",
      "          Conv2d-441           [-1, 64, 56, 56]           8,256\n",
      "      DoubleConv-442           [-1, 64, 56, 56]               0\n",
      "              Up-443           [-1, 64, 56, 56]               0\n",
      " ConvTranspose2d-444         [-1, 48, 112, 112]          12,336\n",
      "          Conv2d-445           [-1, 48, 56, 56]          41,520\n",
      "     BatchNorm2d-446           [-1, 48, 56, 56]              96\n",
      "            ReLU-447           [-1, 48, 56, 56]               0\n",
      "          Conv2d-448           [-1, 48, 56, 56]          20,784\n",
      "     BatchNorm2d-449           [-1, 48, 56, 56]              96\n",
      "            ReLU-450           [-1, 48, 56, 56]               0\n",
      "          Conv2d-451           [-1, 48, 56, 56]           4,656\n",
      "      DoubleConv-452           [-1, 48, 56, 56]               0\n",
      "              Up-453           [-1, 48, 56, 56]               0\n",
      " ConvTranspose2d-454         [-1, 24, 112, 112]           4,632\n",
      "          Conv2d-455           [-1, 24, 56, 56]          10,392\n",
      "     BatchNorm2d-456           [-1, 24, 56, 56]              48\n",
      "            ReLU-457           [-1, 24, 56, 56]               0\n",
      "          Conv2d-458           [-1, 24, 56, 56]           5,208\n",
      "     BatchNorm2d-459           [-1, 24, 56, 56]              48\n",
      "            ReLU-460           [-1, 24, 56, 56]               0\n",
      "          Conv2d-461           [-1, 24, 56, 56]           1,176\n",
      "      DoubleConv-462           [-1, 24, 56, 56]               0\n",
      "              Up-463           [-1, 24, 56, 56]               0\n",
      " ConvTranspose2d-464         [-1, 24, 112, 112]           2,328\n",
      "          Conv2d-465           [-1, 24, 56, 56]          10,392\n",
      "     BatchNorm2d-466           [-1, 24, 56, 56]              48\n",
      "            ReLU-467           [-1, 24, 56, 56]               0\n",
      "          Conv2d-468           [-1, 24, 56, 56]           5,208\n",
      "     BatchNorm2d-469           [-1, 24, 56, 56]              48\n",
      "            ReLU-470           [-1, 24, 56, 56]               0\n",
      "          Conv2d-471           [-1, 24, 56, 56]           1,176\n",
      "      DoubleConv-472           [-1, 24, 56, 56]               0\n",
      "              Up-473           [-1, 24, 56, 56]               0\n",
      " ConvTranspose2d-474          [-1, 1, 112, 112]              97\n",
      "         Sigmoid-475          [-1, 1, 112, 112]               0\n",
      "================================================================\n",
      "Total params: 14,186,337\n",
      "Trainable params: 14,186,337\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1083.86\n",
      "Params size (MB): 54.12\n",
      "Estimated Total Size (MB): 1138.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e649d01-6100-49a7-965f-0e7b2da304d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
