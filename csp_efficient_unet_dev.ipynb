{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247aa212-676d-4176-8cb0-be847d29cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "732ab2fd-96d7-4ce7-8ecc-3e45435bcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#    Author: Aaron Liu\n",
    "#    Email: tl254@duke.edu\n",
    "#    Created on: July 2 2021\n",
    "#    Code structure reference: https://github.com/milesial/Pytorch-UNet\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class CSPLevelBlock(nn.Module):\n",
    "#     \"\"\"(BN ==> ReLU ==> Conv) x 2 + CSP pre-activation shortcut\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels,\n",
    "#         out_channels,\n",
    "#         stride=(1, 1),\n",
    "#         expand_ratio=1.0,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.stride = stride\n",
    "#         exp_channels = int(round(out_channels * expand_ratio))\n",
    "#         self.expand_layer = nn.Sequential(\n",
    "#             nn.BatchNorm2d(in_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels,\n",
    "#                 exp_channels,\n",
    "#                 kernel_size=1,\n",
    "#                 bias=False,\n",
    "#                 stride=self.stride[0],\n",
    "#             ),\n",
    "#         )\n",
    "#         in_channels = exp_channels // 2\n",
    "#         self.stride = stride\n",
    "#         self.double_conv = nn.Sequential(\n",
    "#             nn.BatchNorm2d(in_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels,\n",
    "#                 in_channels,\n",
    "#                 kernel_size=3,\n",
    "#                 padding=1,\n",
    "#                 stride=self.stride[1],\n",
    "#                 bias=False,\n",
    "#             ),\n",
    "#             nn.BatchNorm2d(in_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels,\n",
    "#                 in_channels,\n",
    "#                 kernel_size=3,\n",
    "#                 padding=1,\n",
    "#                 stride=self.stride[1],\n",
    "#                 bias=False,\n",
    "#             ),\n",
    "#         )\n",
    "#         self.shortcut = nn.Conv2d(in_channels, in_channels, 1, bias=False)\n",
    "\n",
    "#         self.partial_trans2 = nn.Sequential(\n",
    "#             nn.BatchNorm2d(in_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(in_channels, in_channels, 1, bias=False),\n",
    "#         )\n",
    "\n",
    "#         self.partial_trans_head = nn.Sequential(\n",
    "#             nn.BatchNorm2d(exp_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(exp_channels, out_channels, 1, bias=False),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.expand_layer(x)\n",
    "#         half = x.size(1) // 2\n",
    "#         part1, part2 = x[:, :half], x[:, half:]\n",
    "#         part2 = self.partial_trans2((self.double_conv(part2) + self.shortcut(part2)))\n",
    "#         x = self.partial_trans_head(torch.cat([part1, part2], dim=1))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class LevelBlock(nn.Module):\n",
    "#     \"\"\"(BN ==> ReLU ==> Conv) x 2 + pre-activation shortcut\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels,\n",
    "#         out_channels,\n",
    "#         mid_channels=None,\n",
    "#         stride=(1, 1),\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         if not mid_channels:\n",
    "#             mid_channels = out_channels\n",
    "#         self.stride = stride\n",
    "#         self.double_conv = nn.Sequential(\n",
    "#             nn.BatchNorm2d(in_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels,\n",
    "#                 mid_channels,\n",
    "#                 kernel_size=3,\n",
    "#                 padding=1,\n",
    "#                 stride=self.stride[0],\n",
    "#                 bias=False,\n",
    "#             ),\n",
    "#             nn.BatchNorm2d(mid_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(\n",
    "#                 mid_channels,\n",
    "#                 out_channels,\n",
    "#                 kernel_size=3,\n",
    "#                 padding=1,\n",
    "#                 stride=self.stride[1],\n",
    "#                 bias=False,\n",
    "#             ),\n",
    "#         )\n",
    "#         self.shortcut = nn.Conv2d(\n",
    "#             in_channels, out_channels, 1, stride=self.stride[0], bias=False\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.double_conv(x) + self.shortcut(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Down(nn.Module):\n",
    "#     \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels, stride=(1, 1), use_csp=True):\n",
    "#         super().__init__()\n",
    "#         self.stride = stride\n",
    "#         if use_csp:\n",
    "#             self.level_block = CSPLevelBlock(\n",
    "#                 in_channels, out_channels, stride=self.stride\n",
    "#             )\n",
    "#         else:\n",
    "#             self.level_block = LevelBlock(in_channels, out_channels, stride=self.stride)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.level_block(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Up(nn.Module):\n",
    "#     \"\"\"Upscaling\"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels, stride=(1, 1), use_csp=True):\n",
    "#         super().__init__()\n",
    "#         self.stride = stride\n",
    "#         self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "#         if use_csp:\n",
    "#             self.level_block = CSPLevelBlock(\n",
    "#                 in_channels, out_channels, stride=self.stride\n",
    "#             )\n",
    "#         else:\n",
    "#             self.level_block = LevelBlock(in_channels, out_channels, stride=self.stride)\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         x1 = self.up(x1)\n",
    "#         diffY = x2.size()[2] - x1.size()[2]\n",
    "#         diffX = x2.size()[3] - x1.size()[3]\n",
    "#         x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "#         x = torch.cat([x2, x1], dim=1)\n",
    "#         x = self.level_block(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Stem(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, use_csp=True, expand_ratio=1.0):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.use_csp = 0\n",
    "#         if use_csp:\n",
    "#             self.use_csp = 1\n",
    "#             exp_channels = int(round(out_channels * expand_ratio))\n",
    "#             self.expand_layer = nn.Sequential(\n",
    "#                 nn.BatchNorm2d(in_channels),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(\n",
    "#                     in_channels,\n",
    "#                     exp_channels,\n",
    "#                     kernel_size=1,\n",
    "#                     bias=False,\n",
    "#                 ),\n",
    "#             )\n",
    "#             in_channels = exp_channels // 2\n",
    "#             self.stem_block = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),\n",
    "#                 nn.BatchNorm2d(in_channels),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),\n",
    "#             )\n",
    "#             self.shortcut = nn.Conv2d(in_channels, in_channels, 1, bias=False)\n",
    "\n",
    "#             self.partial_trans2 = nn.Sequential(\n",
    "#                 nn.BatchNorm2d(in_channels),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(in_channels, in_channels, 1, bias=False),\n",
    "#             )\n",
    "\n",
    "#             self.partial_trans_head = nn.Sequential(\n",
    "#                 nn.BatchNorm2d(exp_channels),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(exp_channels, out_channels, 1, bias=False),\n",
    "#             )\n",
    "#         else:\n",
    "#             self.stem_block = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "#                 nn.BatchNorm2d(out_channels),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
    "#             )\n",
    "#             self.shortcut = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.use_csp:\n",
    "#             x = self.expand_layer(x)\n",
    "#             half = x.size(1) // 2\n",
    "#             part1, part2 = x[:, :half], x[:, half:]\n",
    "#             print(self.stem_block(part2).shape)\n",
    "#             part2 = self.partial_trans2((self.stem_block(part2) + self.shortcut(part2)))\n",
    "#             x = self.partial_trans_head(torch.cat([part1, part2], dim=1))\n",
    "#         else:\n",
    "#             x = self.stem_block(x) + self.shortcut(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c16cf7d-243d-403e-a927-3c893eda5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#    Author: Aaron Liu\n",
    "#    Email: tl254@duke.edu\n",
    "#    Created on: July 2 2021\n",
    "# \"\"\"\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class CSPResUNet(nn.Module):\n",
    "#     def __init__(self, n_channels, n_classes, use_csp=True):\n",
    "#         super(CSPResUNet, self).__init__()\n",
    "#         self.n_channels = n_channels\n",
    "#         self.n_classes = n_classes\n",
    "\n",
    "#         # Encoding\n",
    "#         self.stem = Stem(n_channels, 64, use_csp=False)\n",
    "#         self.down1 = Down(64, 128, stride=(2, 1), use_csp=use_csp)\n",
    "#         self.down2 = Down(128, 256, stride=(2, 1), use_csp=use_csp)\n",
    "#         self.down3 = Down(256, 512, stride=(2, 1), use_csp=use_csp)\n",
    "\n",
    "#         self.up1 = Up(512, 256, stride=(1, 1), use_csp=use_csp)\n",
    "#         self.up2 = Up(256, 128, stride=(1, 1), use_csp=use_csp)\n",
    "#         self.up3 = Up(128, 64, stride=(1, 1), use_csp=use_csp)\n",
    "\n",
    "#         self.outconv = nn.Conv2d(64, n_classes, 1, bias=False)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1 = self.stem(x)\n",
    "#         x2 = self.down1(x1)\n",
    "#         x3 = self.down2(x2)\n",
    "#         x4 = self.down3(x3)\n",
    "#         x = self.up1(x4, x3)\n",
    "#         x = self.up2(x, x2)\n",
    "#         x = self.up3(x, x1)\n",
    "#         x = self.outconv(x)\n",
    "#         x = self.sigmoid(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb843c14-69ab-4f7f-be7a-ebd8eff50f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cspresunet import CSPResUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec30f3d-6761-48c6-82ce-116a1ebe0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSPResUNet(1, 1, use_csp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398f1f57-f0f0-49b6-98df-5a8e938963bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 1, 112, 112)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e90010-6790-43a4-bb10-7994880f646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca910d-48e4-40ca-9938-3689003d6662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
